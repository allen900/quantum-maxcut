{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Max-Cut with QAOA\n",
    "\n",
    "## Brief Problem Description\n",
    "\n",
    "The problem of interest is the weighted max cut problem. Given a set of vertices and weighted edges connecting some of the vertices, we are interested in separating the vertices into two sets such that the sum of the weights of the edges between the sets is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import Qconfig\n",
    "from tqdm import tqdm\n",
    "from random import randint, choice, uniform\n",
    "from math import ceil\n",
    "from statistics import stdev, mean\n",
    "from skopt import gbrt_minimize, dummy_minimize, forest_minimize, gp_minimize\n",
    "from qiskit import register, available_backends, QuantumCircuit, QuantumRegister, \\\n",
    "        ClassicalRegister, execute\n",
    "\n",
    "register(Qconfig.APItoken, Qconfig.config[\"url\"])\n",
    "pbar = None\n",
    "DEBUG = False\n",
    "\n",
    "def debug(string):\n",
    "    if DEBUG:\n",
    "        sys.stdout.write(string)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Encoding\n",
    "\n",
    "In order for a problem to be solvable using QAOA, it must satisfy  two main requirements. One must to be able to:\n",
    " - Encode a candidate solution to the problem using a string of qubits.\n",
    " - Evaluate the 'cost' of a candidate solution with a one or more cost operators.\n",
    " \n",
    "### Candidate Solutions\n",
    "\n",
    "In the case of Weighted Max Cut, we are a given a graph with N nodes and E edges, and we need to be able to encode a 'cut' of the graph in a bitstring. We are able to accomplish this by giving each node a distinct index from 0 to n-1. Thus, an n-length bitstring can encode a 'cut' to the graph, where one cut contains all the nodes with a 0 at their index into the bitstring, and the other contains nodes with a 1. Below is code containing the logic required to build random problem instances, evaluate candidate bitstring solutions, and determine the maximum possible cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph():\n",
    "    def __init__(self, N, randomize=True):\n",
    "        ''' Initialize a random graph with N vertices. '''\n",
    "        self.N = N\n",
    "        self.E = 0\n",
    "        self.adj = {n:dict() for n in range(N)}\n",
    "\n",
    "        # For storing information about each run.\n",
    "        self.currentScore = float('-inf')\n",
    "        self.currentBest = \"\"\n",
    "        self.runs = []\n",
    "\n",
    "        # Randomly generate edges.\n",
    "        if randomize:\n",
    "            self.randomize()\n",
    "\n",
    "    def randomize(self):\n",
    "        ''' Randomly generate edges for this graph. '''\n",
    "\n",
    "        # Generate list of tuples for all possible directed edges.\n",
    "        all_possible_edges = set([(x,y) for x in range(self.N) for y in range(self.N) if x != y])\n",
    "\n",
    "        # Sanity check, ensuring we generated the correct number of edges.\n",
    "        e_gen = len(all_possible_edges) / 2\n",
    "        e_shd = self.N * (self.N-1) / 2\n",
    "        assert e_gen == e_shd , \"%d != %d\" % (e_gen, e_shd)\n",
    "\n",
    "        # Choose a random number of edges for this graph to have. \n",
    "        # Note, we stop at len/2 because we generated directed edges,\n",
    "        # so each edge counts twice.\n",
    "        num_edges = randint(1, len(all_possible_edges)/2)\n",
    "        for i in range(num_edges):\n",
    "            # Choose an edge, remove it and its directed complement from the list.\n",
    "            e = choice(list(all_possible_edges))\n",
    "            all_possible_edges.remove(e)\n",
    "            all_possible_edges.remove(e[::-1])\n",
    "\n",
    "            # Unpack tuple into vertex ints.\n",
    "            u, v = int(e[0]), int(e[1])\n",
    "\n",
    "            # Choose a random weight for each edge.\n",
    "            weight = randint(1, 100)\n",
    "\n",
    "            #weight = 1\n",
    "            self.add_edge(u, v, weight)\n",
    "\n",
    "\n",
    "    def add_edge(self, u, v, weight):\n",
    "        ''' Add an edge to the graph. '''\n",
    "        self.E += 1\n",
    "        self.adj[u][v] = weight\n",
    "\n",
    "    def get_edges(self):\n",
    "        ''' Get a list of all edges. '''\n",
    "        edges = []\n",
    "        for u in self.adj:\n",
    "            for v in self.adj[u]:\n",
    "                edges.append((u, v, self.adj[u][v]))\n",
    "        return edges\n",
    "\n",
    "    def get_score(self,bitstring):\n",
    "        ''' Score a candidate solution. '''\n",
    "        assert len(bitstring) == self.N\n",
    "\n",
    "        score = 0\n",
    "\n",
    "        # For every edge u,v in the graph, add the weight\n",
    "        # of the edge if u,v belong to different cuts\n",
    "        # given this candidate solution.\n",
    "\n",
    "        for u in self.adj:\n",
    "            for v in self.adj[u]:\n",
    "                if bitstring[u] != bitstring[v]:\n",
    "                    score += self.adj[u][v]\n",
    "        return score\n",
    "\n",
    "    def optimal_score(self):\n",
    "        '''\n",
    "        Returns (score, solutions) holding the best possible solution to the\n",
    "        MaxCut problem with this graph.\n",
    "        '''\n",
    "\n",
    "        best = 0\n",
    "        best_val = []\n",
    "\n",
    "        # Iterate over all possible candidate bitstrings\n",
    "        # Note: the bitstrings from 0 - N/2 are symmetrically\n",
    "        # equivalent to those above\n",
    "        for i in range(ceil((2 ** self.N)/2)):\n",
    "            # Convert number to 0-padded bitstring.\n",
    "            bitstring = bin(i)[2:]\n",
    "            bitstring = (self.N - len(bitstring)) * \"0\" + bitstring\n",
    "\n",
    "            sc = self.get_score(bitstring)\n",
    "            if sc > best:\n",
    "                best = sc\n",
    "                best_val = [bitstring]\n",
    "            elif sc == best:\n",
    "                best_val.append(bitstring)\n",
    "        return best, best_val\n",
    "\n",
    "    def update_score(self, bitstring):\n",
    "        ''' Scores the given bitstring and keeps track of best. '''\n",
    "        score = self.get_score(bitstring)\n",
    "        if score > self.currentScore:\n",
    "            self.currentScore = score\n",
    "            self.currentBest = bitstring\n",
    "        return score\n",
    "    \n",
    "    def clear_runs(self):\n",
    "        ''' Clear data from past runs. '''\n",
    "        self.currentScore = float('-inf')\n",
    "        self.currentBest = \"\"\n",
    "        self.runs = []\n",
    "        \n",
    "    def add_run(self, gamma, beta, expected_value):\n",
    "        ''' Save the data from each run iteration. '''\n",
    "        self.runs.append([gamma, beta, expected_value])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Graph with %d vertices %d edges.\\nAdjacency List: %s\" % (self.N, self.E, self.adj)\n",
    "\n",
    "# Sample graph.\n",
    "g = Graph(5)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "We can evaluate a candidate solution by applying a 'cost' operator to each pair of nodes that share an edge. In particular, for every edge (u,v) in the graph, we apply a cost operator that:\n",
    "  - Applies a phase of $e^{i w \\gamma}$, the weight of the edge, to both qubits encoding those nodes if they belong to different cuts.\n",
    "  - Does nothing if they belong to the same cut.\n",
    "  \n",
    "The cost operator shown below implements the above constraints:\n",
    "![Cost Operator](img/cost.gif)\n",
    "\n",
    "\n",
    "This cost operator can be equivalently represented by $\\frac{w}{2}(I-Z_1Z_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QAOA Description\n",
    "\n",
    "QAOA works in two stages: a quantum computing stage and a classical stage.\n",
    "\n",
    "### Quantum Stage:\n",
    "\n",
    "The quantum stage takes in two parameters, gamma and beta, and a tuning hyperparameter p. In general, increasing p is guaranteed not to make your solution worse, though there may be diminishing returns after a certain point. For our application, we chose a p of 1, as even with p=1 we were consistently able to find the optimal solution on the problem sizes we could simulate.\n",
    "\n",
    "First, n qubits are prepared in a superposition over all candidate solutions. Gates are then applied like so: $W_pV_p$ ... $W_1V_1$ |$\\Phi$>, where W and V refer to Hamiltonians encoding the cost and driver functions (defined in detail below). To calculate the expected value, we measure the input state several times, getting several candidate solutions along with the amount of times they occur. For each candidate solution, we evaulate it's cost and multiply it by the probability of that solution occuring (where probability is the number of times we measured it divided by the total number of shots). This is generalized below:\n",
    "```\n",
    "EXP = P(state ‘000..0’) * cost(‘000..0’) + … + P(state ‘111..1’) * cost(‘111..1’)\n",
    "```\n",
    "\n",
    "### Classical Stage:\n",
    "\n",
    "In the classical stage, two parameters gamma and beta are randomly chosen and fed into the quantum stage, getting an expectation value. We then run a classical optimizer over gamma and beta, using the quantum stage as our 'black-box' cost function, until we are satsified with the expectation value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and Driver Hamiltonians C and B:\n",
    "\n",
    "The cost hamiltonian V can be expressed by $e^{-i \\gamma C}$, where C is a global cost operator. In the case of Weighted Max Cut, we can express the cost operator as a sum of the local cost operators, which act on pairs of qubits sharing an edge, defined above. For each of the qubits corresponding to the vertices of that edge, we apply a phase of $e^{i w \\gamma}$, where $w$ is the weight of the edge between those two qubits.\n",
    "\n",
    "The driver hamiltonian W can be expressed by $e^{-i \\beta B}$, where B is the an operator that flips all the input qubits. \n",
    "\n",
    "Below is some code that, given $\\beta, \\gamma$, prepares and evaluates the \"Quantum Stage\" of the algorithm described above, returning an expectation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expectation(x, g, NUM_SHOTS=1024):\n",
    "    # Look for progress bar as a global variable.\n",
    "    global pbar\n",
    "    \n",
    "    gamma, beta = x\n",
    "\n",
    "    debug(\"Cost of Gamma: %s, beta: %s... \" % (gamma, beta))\n",
    "\n",
    "    # Construct quantum circuit.\n",
    "    q = QuantumRegister(g.N)\n",
    "    c = ClassicalRegister(g.N)\n",
    "    qc = QuantumCircuit(q, c)\n",
    "\n",
    "    # Apply hadamard to all inputs.\n",
    "    for i in range(g.N):\n",
    "        qc.h(q[i])\n",
    "\n",
    "    # Apply V for all edges.\n",
    "    for edge in g.get_edges():\n",
    "        u, v, w = edge\n",
    "\n",
    "        # Apply CNots.\n",
    "        qc.cx(q[u], q[v])\n",
    "\n",
    "        qc.u1(gamma*w, q[v])\n",
    "\n",
    "        # Apply CNots.\n",
    "        qc.cx(q[u], q[v])\n",
    "\n",
    "    # Apply W to all vertices.\n",
    "    for i in range(g.N):\n",
    "        qc.h(q[i])\n",
    "        qc.u1(-2*beta, q[i])\n",
    "        qc.h(q[i])\n",
    "\n",
    "\n",
    "    # Measure the qubits.\n",
    "    for i in range(g.N):\n",
    "        qc.measure(q[i], c[i])\n",
    "\n",
    "    # Run the simluator.\n",
    "    job = execute(qc, backend='ibmq_qasm_simulator', shots=NUM_SHOTS)\n",
    "    results = job.result()\n",
    "    result_dict = results.get_counts(qc)\n",
    "\n",
    "    debug(\"done!\\n\")\n",
    "\n",
    "    # Calculate the expected value of the candidate bitstrings.\n",
    "    exp = 0\n",
    "    for bitstring in result_dict:\n",
    "        prob = np.float(result_dict[bitstring]) / NUM_SHOTS\n",
    "        score = g.update_score(bitstring)\n",
    "\n",
    "        # Expected value is the score of each bitstring times\n",
    "        # probability of it occuring.\n",
    "        exp += score * prob\n",
    "\n",
    "    debug(\"\\tExpected Value: %s\\n\" % (exp))\n",
    "    debug(\"\\tBest Found Solution: %s, %s\\n\" % (g.currentScore, g.currentBest))\n",
    "\n",
    "    g.add_run(gamma, beta, exp)\n",
    "\n",
    "    # Try updating progress bar if defined.\n",
    "    try:\n",
    "        pbar.update(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return exp # bc we want to minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma/Beta vs. Expectation\n",
    "\n",
    "Before choosing a classical optimizer, we first wanted to plot the gradients of both gamma and beta to see what types of gradients we were attempting to optimize over. Below is the code we used and some graphs of the gradients of both gamma and beta with all other variables held constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_constant(vary=\"beta\"):\n",
    "    ''' Plots expected value vs. gamma/beta, holding the rest of the variables constant.'''\n",
    "    # Choose some random starting beta/gamma and graph.\n",
    "    lim = np.pi if vary == \"gamma\" else 2*np.pi\n",
    "    constant_var = uniform(0, lim)\n",
    "    g = Graph(5)\n",
    "\n",
    "    # RUNS # of runs at each gamma for error bars.\n",
    "    RUNS = 3\n",
    "\n",
    "    # Keep track of gammas, expected values, for plotting.\n",
    "    pts, exp, std = [], [], []\n",
    "\n",
    "    # The maximum possible expected value is the maximum possible weighted cut.\n",
    "    opt = g.optimal_score()[0]\n",
    "    debug(\"Optimal score: %s\\n\" % (opt))\n",
    "    \n",
    "    # Number of data points to collect.\n",
    "    NUM_RUNS = 3\n",
    "    MIN = 0\n",
    "    MAX = 2*np.pi if vary == \"gamma\" else np.pi\n",
    "    \n",
    "    # For progress bar.\n",
    "    global pbar\n",
    "    pbar = tqdm(total=NUM_RUNS*RUNS)\n",
    "    \n",
    "    points = np.linspace(MIN, MAX, NUM_RUNS)\n",
    "    for point in points:\n",
    "        pts.append(point)\n",
    "\n",
    "        # Calculate expected values.\n",
    "        vals = []\n",
    "        for i in range(RUNS):\n",
    "        \n",
    "            # Params are passed in as gamma, beta, so order matters.\n",
    "            params = [point, constant_var] if vary == \"gamma\" else [constant_var, point]\n",
    "            vals.append(get_expectation(params, g))\n",
    "\n",
    "        # Calculate mean, standard deviation.\n",
    "        exp.append(mean(vals))\n",
    "        std.append(stdev(vals))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.errorbar(x=pts, y=exp, yerr=std, fmt='o-', markersize=10)\n",
    "    ax.legend(loc=2)\n",
    "\n",
    "    # Names for plotting.\n",
    "    vary_name = \"Gamma\" if vary == \"gamma\" else \"Beta\"\n",
    "    const_name = \"Beta\" if vary_name == \"Gamma\" else \"Gamma\"\n",
    "    \n",
    "    ax.set_title(\"Effect of Varying %s with %s = %s\" % (vary_name, const_name, constant_var))\n",
    "    ax.set_xlabel(\"%s\" % (vary_name)) \n",
    "    ax.set_ylabel(\"Expected Value\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "#hold_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gamma vs. exp](img/gamma_change.png)\n",
    "![beta vs.exp](img/beta_change.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! The above plots look pretty promising, and seem to imply that a gradient-based optimizer should be able to find local maxima nicely. **However**, these graphs are misleading. It actually took us a good three or four runs to get graphs with a smooth gradient. Most of the runs looked more like:\n",
    "\n",
    "![Bad Gamma](img/gamma_weird.png)\n",
    "\n",
    "## Evaluating Gradients\n",
    "\n",
    "From creating several plots, we learned that the gradients were very noisy with respect to other constant variables. For example, changing the constant value of beta slightly would produce an entirely different gradient for gamma. Even without changing the constant variables, the gradients would be very different across runs! \n",
    "\n",
    "An interesting note is that the gradient of beta was consistently smoother than that of gamma. Though we chose not to explore it, it could be possible to choose gamma randomly and run gradient-based optimization over just beta.\n",
    "\n",
    "### Choosing Classical Optimizers\n",
    "\n",
    "We evaluated several different classical optimizers. We originally started with \"gradient descent\" optimizers, which work by, given starting beta/gamma values, perturb them slightly in order to approximate the local gradient and then jump. However, we noticed that the jump seemed to increase/decrease the expectation value with equal probability. In other words, the local gradient approximation was not very accurate. This is likely due to the large amount of noise present in the gradients: slighting perturbing the values of beta/gamma, like we found earlier, could result in huge changes in expected value.\n",
    "\n",
    "Another problem with gradient descent optimizers is that they, in general, require many function evaluations at each step. The Scikit-learn optimizer we were initially using used four different function evaluations to calculate the gradient (likely associated with increasing/decreasing beta/gamma). In our case, where function evaluations are so expensive, this overhead was too much.\n",
    "\n",
    "#### Scikit-Optimize\n",
    "\n",
    "We eventually stumbled across [Scikit-Optimize](https://scikit-optimize.github.io/), a set of optimization functions built specifically to minimize calls to expensive black-box functions. Below is a brief description of the four we evaluated:\n",
    "  - *Forest_Minimize* - Uses sequential decision trees.\n",
    "  - *Gbrt_Minimize*   - Uses Gradient Boosted decision trees.\n",
    "  - *Gp_Minimize*     - Uses good 'ole Baynesian regression.\n",
    "  - *Dummy_Minimize*  - Randomly chooses points from the sample space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot different types of optimizers.\n",
    "def compare_optimizers(num_instances=4, graph_size=15, n_calls=8, n_random_starts=2):\n",
    "    global pbar\n",
    "    pbar = None\n",
    "    \n",
    "    # For progress bar.\n",
    "    pbar = tqdm(total=num_instances*n_calls*4)\n",
    "    \n",
    "    instances = [Graph(graph_size) for _ in range(num_instances)]\n",
    "    \n",
    "    # Percent of optimal score acheived by each algorithm.\n",
    "    dummy = []\n",
    "    decision_trees = []\n",
    "    gradient_boosted_trees = []\n",
    "    baynesian = []\n",
    "    \n",
    "    # For each instance, run each algorithm.\n",
    "    for inst in instances:\n",
    "        # Scikit functions only take in parameters and want to minimize values.\n",
    "        # Create a wrapper function to format get_expectation.\n",
    "        sk_get_exp = lambda x: -1*get_expectation(x, inst)\n",
    "\n",
    "        \n",
    "        opt = inst.optimal_score()[0]\n",
    "        \n",
    "        # Dummy.\n",
    "        inst.clear_runs()\n",
    "        dummy_minimize(func=sk_get_exp,\n",
    "                      dimensions=[(0,2*np.pi),(0,np.pi)],\n",
    "                      n_calls=n_calls)\n",
    "        dummy.append(float(inst.currentScore) / opt)\n",
    "\n",
    "        # Decision Trees.\n",
    "        inst.clear_runs()\n",
    "        forest_minimize(func=sk_get_exp,\n",
    "                      dimensions=[(0,2*np.pi),(0,np.pi)],\n",
    "                      n_calls=n_calls,\n",
    "                      n_random_starts=n_random_starts)\n",
    "        decision_trees.append(float(inst.currentScore) / opt)\n",
    "        \n",
    "        # Gradient Boosted Decision Trees.\n",
    "        inst.clear_runs()\n",
    "        gbrt_minimize(func=sk_get_exp,\n",
    "                      dimensions=[(0,2*np.pi),(0,np.pi)],\n",
    "                      n_calls=n_calls,\n",
    "                      n_random_starts=n_random_starts)\n",
    "        gradient_boosted_trees.append(float(inst.currentScore) / opt)\n",
    "        \n",
    "        # Baynesian.\n",
    "        inst.clear_runs()\n",
    "        gp_minimize(func=sk_get_exp,\n",
    "                      dimensions=[(0,2*np.pi),(0,np.pi)],\n",
    "                      n_calls=n_calls,\n",
    "                      n_random_starts=n_random_starts)\n",
    "        baynesian.append(float(inst.currentScore) / opt)\n",
    "\n",
    "    # Compare mean/stdev of % opt. achieved for each algorithm.\n",
    "    print(\"-- % of Optimal Achieved, Mean and Std. Dev --\")\n",
    "    print(\"Random Sampling:\\nMean: %s\\nStd. Dev: %s\" % (mean(dummy), stdev(dummy)))\n",
    "    print(\"Decision Trees:\\nMean: %s\\nStd. Dev: %s\" % (mean(decision_trees), stdev(decision_trees)))\n",
    "    print(\"Gradient Boosted Decision Trees:\\nMean: %s\\nStd. Dev: %s\" % (mean(gradient_boosted_trees), stdev(gradient_boosted_trees)))\n",
    "    print(\"Baynesian Optimization:\\nMean: %s\\nStd. Dev: %s\" % (mean(baynesian), stdev(baynesian)))\n",
    "    \n",
    "#compare_optimizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Results\n",
    "\n",
    "```\n",
    "-- % of Optimal Achieved, Mean and Std. Dev --\n",
    "Random Sampling:\n",
    "    Mean: 0.9918135656630878\n",
    "    Std. Dev: 0.008893516482779347\n",
    "Decision Trees:\n",
    "    Mean: 0.9911853052336336\n",
    "    Std. Dev: 0.013767350119746134\n",
    "Gradient Boosted Decision Trees:\n",
    "    Mean: 0.9874128354367063\n",
    "    Std. Dev: 0.01234703421622558\n",
    "Baynesian Optimization:\n",
    "    Mean: 0.9976966107272129\n",
    "    Std. Dev: 0.00398958725007638\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, all four optimization methods pretty equally well, including random sampling! The fact the all of them achieved so close to optimal seems to suggest that QAOA is pretty efficient at find decent solutions, even with random beta and gamma values and p=1 (at least for this problem size). In addition, our results showed the Baynesian regression was the most accurate and precise optimizer. Though we aren't extremely certain why this is the case, we think it has to do with large amounts of noise.\n",
    "\n",
    "Given that our gradients had small general trends and lots of noise, it makes sense that a normal regression can work well, because as long as their are as many points above as below the true trend line, our approximate trend line should be pretty accurate. Furthermore, regression only needs a couple of points to create a decent trend line. The fact that we were limiting the number of function calls to 8 could be another reason why regression outperformed other optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Results and Discussion\n",
    "\n",
    "### Minimum, Maximum and Mean Costs across Problem Instances\n",
    "\n",
    "After deciding on Baynesian regression as our optimizer, we evaluated our algorithm on several instances of the problem. Below is the code and our plot of expected value and the best score achieved, relative to the maximum possible score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_cost(num_instances=25, num_vert=15, num_runs=4):\n",
    "    '''\n",
    "    For several random problem instances, plot the cost of the output state.\n",
    "    Plot average, maximum and minimum cost.\n",
    "    '''\n",
    "\n",
    "    # Prepare several random instances of the problem.\n",
    "    instances = [Graph(num_vert) for _ in range(num_instances)]\n",
    "\n",
    "    # For progress bar.    \n",
    "    global pbar\n",
    "    pbar = tqdm(total=num_instances*num_runs)\n",
    "\n",
    "    # For holding iteration number and expected values.\n",
    "    its, lows, averages, highs, best_founds = [], [], [], [], []\n",
    "\n",
    "    it = 1\n",
    "    # Calculate expected values using Baynesian Regression.\n",
    "    for graph in instances:\n",
    "        \n",
    "        # Run the optimizer.\n",
    "        sk_get_exp = lambda x: -1*get_expectation(x, graph)\n",
    "        gp_minimize(func=sk_get_exp,\n",
    "                      dimensions=[(0,2*np.pi),(0,np.pi)],\n",
    "                      n_calls=num_runs,\n",
    "                      n_random_starts=max(1, int(num_runs*0.2)))\n",
    "        \n",
    "        # Save results.\n",
    "        its.append(it)\n",
    "        curr_opt = graph.optimal_score()[0]\n",
    "        \n",
    "        # Min/Avg/Max expected values.\n",
    "        exps = [r[2] for r in graph.runs] # extract expected values\n",
    "        lows.append(float(min(exps)) / curr_opt)\n",
    "        averages.append(float(mean(exps)) / curr_opt)\n",
    "        highs.append(float(max(exps)) / curr_opt)\n",
    "\n",
    "        \n",
    "        # Best found result.\n",
    "\n",
    "        best_founds.append(float(graph.currentScore) / curr_opt)\n",
    "        \n",
    "        it += 1\n",
    "\n",
    "    plt.title(\"Costs of Random Instances\")\n",
    "    plt.xlabel(\"Instance Num\")\n",
    "    plt.ylabel(\"% Optimal Achieved\")\n",
    "\n",
    "\n",
    "    plt.plot(its, averages, color='blue', label='Average Cost %')\n",
    "    plt.plot(its, lows, color='green', label='Minimum Cost %')\n",
    "    plt.plot(its, highs, color='orange', label='Maximum Cost %')\n",
    "    plt.plot(its, best_founds, color='red', label='Best Found Cost %')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(\"img/avg_cost.png\")\n",
    "#instance_cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cost across Instances](img/avg_cost_good-magic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that, for problems of size N=15, QAOA is pretty effective at finding close to the optimal solution. It also shows that expected value is very precise, with the min/avg/max lines all basically coinciding with each other. Finally, it shows that expected value is not always an accurate indicator of the best score found. In the case of instance 16, the average expected value was less than 50% of optimal, and yet there was no noticeable dip in the best cost found. However, instance 22's dip in expected value does correlate with a dip in best found cost.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We have no guarantee that QAOA will give us a decent solution, and with p=1, we have even less of a guarantee. However, it seems that QAOA manages to consistently provide solutions within 90% of optimal (at least for our problem size). One thing we noticed when watching the optimizer work, is that the first iteration tended to always start within 80% of the optimal solution, even when we fed in random beta/gamma starting values. It would be interesting to see how well a random candidate bitstring would do compared to random beta/gamma values -- my intuition is that the starting point that QAOA is able to achieve is much better on average than choosing a random candidate solution would be classically. \n",
    "\n",
    "Overall, we were relatively surprised by the performance of QAOA, with and without classical optimization, and we think the results definitely merit more looking into."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
